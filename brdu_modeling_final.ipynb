{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from Bio import Seq, SeqIO\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from tqdm.keras import TqdmCallback\n",
    "import socket\n",
    "import glob\n",
    "import math\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # pick which gpu to use - run nvidia-smi to see which ones are in use\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[3], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "if 'biochem1' in socket.gethostname():\n",
    "    dataPBase = '/avicenna/vramani/analyses/pacbio/'\n",
    "    figPBase = '/avicenna/cmcnally/pbanalysis/'\n",
    "if 'assembler4' in socket.gethostname():\n",
    "    dataPBase = '/data/users/goodarzilab/mostrowski/pacbio/data/'\n",
    "if 'titan4' in socket.gethostname():\n",
    "    dataPBase = '/data/users/goodarzilab/mostrowski/pacbio/data/'\n",
    "if 'wynton' in socket.gethostname():\n",
    "    dataPBase = '/wynton/group/goodarzilab/ramanilab/results/pacbio/'\n",
    "if 'rumi' in socket.gethostname():\n",
    "    raise Exception('no pacbio results folder on rumi')\n",
    "    \n",
    "    \n",
    "sampleRef = pd.concat([pd.read_csv(dataPBase + '210520_NA_K562Brdu_repeat/210520_NA_K562Brdu_repeat.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '210930_MO_E14_K562_BrdU/210930_MO_E14_K562_BrdU.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '211014_MO_BrdU_invivo/211014_MO_BrdU_invivo.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '220722_BrdUTP_methcontrols/220722_BrdUTP_methcontrols.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '220722_BrdU_K562_invivopulse/220722_BrdU_K562_invivopulse.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '211203_MO_BrdU_invo_1013/211203_MO_BrdU_invo_1013.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '220128_MO_BrdU_shear_CM_spike-in/220128_MO_BrdU_shear_CM_spike-in.sampleReference_MO.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '220920_MO_BrdU_invivo/220920_MO_BrdU_invivo.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '221109_MO_BrdU_invivo/221109_MO_BrdU_invivo.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '221017_MO_CTCFdegron_RASAM/221017_MO_CTCFdegron_RASAM.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230419_MO_K562_RASAM_1/230419_MO_K562_RASAM_1.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230419_MO_K562_RASAM_2/230419_MO_K562_RASAM_2.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230419_MO_CTCFdegron_RASAM/230419_MO_CTCFdegron_RASAM.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230419_MO_NIPBLdegron_RASAM/230419_MO_NIPBLdegron_RASAM.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230425_e14_RASAM_Cell1/230425_e14_RASAM_Cell1.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230425_e14_RASAM_Cell2/230425_e14_RASAM_Cell2.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230425_e14_RASAM_Cell3/230425_e14_RASAM_Cell3.sampleReference.wynton.csv',index_col=0),\n",
    "                       pd.read_csv(dataPBase + '230425_e14_RASAM_Cell4/230425_e14_RASAM_Cell4.sampleReference.wynton.csv',index_col=0)],\n",
    "                      ignore_index=True)\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.dpi']= 120\n",
    "\n",
    "sampleRef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making files formatted for reading into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge block files if necessary\n",
    "\n",
    "usesamples = range(0,10)\n",
    "\n",
    "for samp in usesamples:\n",
    "    import glob\n",
    "\n",
    "    hmmPieces = glob.glob('{0}{1}/processed/full/{1}_{2}_block*_full.pickle'.format(dataPBase,sampleRef['cell'][samp],\n",
    "                                                                                    sampleRef['sampleName'][samp]))\n",
    "    hmmPieces = sorted(hmmPieces)\n",
    "\n",
    "    hmmAll = {}\n",
    "\n",
    "    for piece in tqdm(hmmPieces, position=0):\n",
    "        with open(piece,'rb') as fopen:\n",
    "            hmmPart = pickle.load(fopen)\n",
    "        hmmAll.update(hmmPart)\n",
    "\n",
    "    with open('{0}{1}/processed/full/{1}_{2}_full.pickle'.format(dataPBase,sampleRef['cell'][samp],\n",
    "                                                                 sampleRef['sampleName'][samp]), 'wb') as fout:\n",
    "        pickle.dump(hmmAll, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNNinput(samp):\n",
    "    baseDic = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    compBase = {'A':'T', 'C':'G', 'G':'C', 'T':'A'}\n",
    "\n",
    "    Nbases = 500\n",
    "\n",
    "    inff = os.path.join(dataPBase, sampleRef['cell'][samp], 'processed', 'full',\n",
    "                        sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_full_zmwinfo.pickle')\n",
    "    zmwinfo = pd.read_pickle(inff)\n",
    "\n",
    "    finff = os.path.join(dataPBase, sampleRef['cell'][samp], 'processed', 'full',\n",
    "                         sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_full.pickle')\n",
    "\n",
    "    with open(finff,'rb') as fopen:\n",
    "        ipdfull = pickle.load(fopen)\n",
    "\n",
    "    nchunk = 0\n",
    "    for ccl in zmwinfo['cclen']:\n",
    "        if ccl >= Nbases:\n",
    "            nchunk += int(np.ceil(ccl / Nbases))\n",
    "\n",
    "    forwardIPD = np.full((nchunk, Nbases, 1), -1, dtype=np.float32)\n",
    "    reverseIPD = np.full((nchunk, Nbases, 1), -1, dtype=np.float32)\n",
    "    forwardNsub = np.full((nchunk, Nbases, 1), -1, dtype=np.int16)\n",
    "    reverseNsub = np.full((nchunk, Nbases, 1), -1, dtype=np.int16)\n",
    "    forwardSeq = np.full((nchunk, Nbases, 4), 0, dtype=np.bool)\n",
    "    reverseSeq = np.full((nchunk, Nbases, 4), 0, dtype=np.bool)\n",
    "    zmwNum = np.full((nchunk, 1), -1, dtype=np.int64)\n",
    "    zmwStartPos = np.full((nchunk, 1), -1, dtype=np.int32)\n",
    "\n",
    "    imol = 0\n",
    "    for zmw in tqdm(zmwinfo['zmw'], position=0, mininterval=1,\n",
    "                    desc='{0}__{1}'.format(sampleRef['cell'][samp], sampleRef['sampleName'][samp])):\n",
    "        ccl = len(ipdfull[zmw]['read'])\n",
    "        if ccl < Nbases:\n",
    "            continue\n",
    "        npiece = int(np.ceil(ccl / Nbases))\n",
    "        interstarts = np.rint(np.interp(np.arange(1,npiece-1), [0, npiece-1], [0, ccl-Nbases])).astype('int')\n",
    "        startp = np.concatenate([[0], interstarts, [ccl-Nbases]])\n",
    "\n",
    "        ipdz = ipdfull[zmw]\n",
    "        seq = ipdz['read']\n",
    "        for ich in range(npiece):\n",
    "            usebases = np.arange(startp[ich], startp[ich]+Nbases)\n",
    "            zmwNum[imol,0] = zmw\n",
    "            zmwStartPos[imol,0] = startp[ich]\n",
    "            forwardIPD[imol,:,0] = ipdz['forwardM'][usebases]\n",
    "            reverseIPD[imol,:,0] = ipdz['reverseM'][usebases]\n",
    "            forwardNsub[imol,:,0] = ipdz['forwardNSub'][usebases]\n",
    "            reverseNsub[imol,:,0] = ipdz['reverseNsub'][usebases]\n",
    "            for ib, b in enumerate(usebases):\n",
    "                forwardSeq[imol,ib,baseDic[seq[b]]] = True\n",
    "                reverseSeq[imol,ib,baseDic[compBase[seq[b]]]] = True\n",
    "            imol += 1\n",
    "\n",
    "    forwardIPD[np.isnan(forwardIPD)] = -1\n",
    "    reverseIPD[np.isnan(reverseIPD)] = -1\n",
    "\n",
    "    if not os.path.exists(dataPBase + '%s/processed/forNN' % (sampleRef['cell'][samp])):\n",
    "        os.makedirs(dataPBase + '%s/processed/forNN' % (sampleRef['cell'][samp]))\n",
    "\n",
    "    np.savez(os.path.join(dataPBase, sampleRef['cell'][samp],'processed','forNN',\n",
    "                          '{0}_{1}_forCNN_preds.npz'.format(sampleRef['cell'][samp],\n",
    "                                                            sampleRef['sampleName'][samp])), \n",
    "             forwardIPD = forwardIPD,\n",
    "             reverseIPD = reverseIPD,\n",
    "             forwardNsub = forwardNsub,\n",
    "             reverseNsub = reverseNsub,\n",
    "             forwardSeq = forwardSeq,\n",
    "             reverseSeq = reverseSeq,\n",
    "             zmwNum = zmwNum,\n",
    "             zmwStartPos = zmwStartPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in range(0,10):\n",
    "    makeCNNinput(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and get it set up for the model\n",
    "\n",
    "usesamples = [0,1,2,3,8,9,10,11,12,13,14,15,16,17,19,20,27,28,29,30,31]\n",
    "\n",
    "\n",
    "weight24h = 0.8\n",
    "weightPCR50 = 0.5\n",
    "\n",
    "sampBrdud = {0:0, 1:0, 2:0, 3:0, 8:weight24h, 9:weight24h, 10:weight24h, 11:weight24h, 12:0, 13:0, 14:0, 15:1, \n",
    "             16:0, 17:1, 19:0, 20:0, 27:weight24h, 28:weight24h, 29:weightPCR50, 30:weightPCR50, 31:1, 43:0, \n",
    "             44:0, 51:1, 52:1, 53:0, 56:1, 57:0, 60:1, 67:1, 71:1, 74:1}\n",
    "\n",
    "## Load in data\n",
    "forwardIPD = []\n",
    "reverseIPD = []\n",
    "forwardNsub = []\n",
    "reverseNsub = []\n",
    "forwardSeq = []\n",
    "reverseSeq = []\n",
    "sampB = []\n",
    "sampW = []\n",
    "sampO = []\n",
    "# training samples take the first 18000 molecules, validation samples take up to the first 40000 \n",
    "\n",
    "for samp in tqdm(usesamples, position=0):\n",
    "\n",
    "    with np.load(os.path.join(dataPBase, sampleRef['cell'][samp],'processed','forNN',\n",
    "                              '{0}_{1}_forCNN_preds.npz'.format(sampleRef['cell'][samp],\n",
    "                                                                sampleRef['sampleName'][samp]))) as data:\n",
    "        usemol = np.arange(data['forwardIPD'].shape[0])\n",
    "        usemol = usemol[0:40000]\n",
    "        forwardIPD.append(data['forwardIPD'][usemol,:,:] - 1)\n",
    "        reverseIPD.append(data['reverseIPD'][usemol,:,:] - 1)\n",
    "        forwardNsub.append((data['forwardNsub'][usemol,:,:] - 25) / 100)\n",
    "        reverseNsub.append((data['reverseNsub'][usemol,:,:] - 25) / 100)\n",
    "        forwardSeq.append(data['forwardSeq'][usemol,:,:])\n",
    "        reverseSeq.append(data['reverseSeq'][usemol,:,:])\n",
    "        sampB.append(np.full((len(usemol),1), sampBrdud[samp]))\n",
    "        sampO.append(np.full((len(usemol),1), samp))\n",
    "\n",
    "forwardIPD = np.concatenate(forwardIPD, axis=0)\n",
    "reverseIPD = np.concatenate(reverseIPD, axis=0)\n",
    "forwardNsub = np.concatenate(forwardNsub, axis=0)\n",
    "reverseNsub = np.concatenate(reverseNsub, axis=0)\n",
    "forwardSeq = np.concatenate(forwardSeq, axis=0)\n",
    "reverseSeq = np.concatenate(reverseSeq, axis=0)\n",
    "sampB = np.concatenate(sampB, axis=0).astype(np.float32)\n",
    "sampO = np.concatenate(sampO, axis=0)\n",
    "\n",
    "forward = np.concatenate([forwardIPD, forwardNsub, forwardSeq], axis=2)\n",
    "reverse = np.concatenate([reverseIPD, reverseNsub, reverseSeq], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training and validation data (s1)\n",
    "\n",
    "trainMol = np.random.choice(forwardIPD.shape[0], int(forwardIPD.shape[0]*0.7), replace=False)\n",
    "validMol = np.setdiff1d(np.arange(forwardIPD.shape[0]), trainMol)\n",
    "\n",
    "trainMol = np.sort(trainMol)\n",
    "validMol = np.sort(validMol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with both max and average pooling (cnn2)\n",
    "\n",
    "forwardInput = keras.layers.Input(forward.shape[1:])\n",
    "reverseInput = keras.layers.Input(reverse.shape[1:])\n",
    "\n",
    "reverseFlip1 = keras.layers.Lambda(lambda x: K.reverse(x,axes=1))(reverseInput)\n",
    "\n",
    "convLayerM = keras.layers.Conv1D(200, 21, kernel_initializer=\"he_uniform\", padding=\"valid\")\n",
    "forwardConvM = convLayerM(forwardInput)\n",
    "reverseConvM = convLayerM(reverseFlip1)\n",
    "\n",
    "convLayerMB1 = keras.layers.BatchNormalization()\n",
    "forwardConvMB1 = convLayerMB1(forwardConvM)\n",
    "reverseConvMB1 = convLayerMB1(reverseConvM)\n",
    "\n",
    "convLayerMA1 = keras.layers.Activation(activation=\"relu\")\n",
    "forwardConvMA1 = convLayerMA1(forwardConvMB1)\n",
    "reverseConvMA1 = convLayerMA1(reverseConvMB1)\n",
    "\n",
    "convLayerM2 = keras.layers.Conv1D(200, 1, kernel_initializer=\"he_uniform\", padding=\"valid\")\n",
    "forwardConvM2 = convLayerM2(forwardConvMA1)\n",
    "reverseConvM2 = convLayerM2(reverseConvMA1)\n",
    "\n",
    "convLayerMB2 = keras.layers.BatchNormalization()\n",
    "forwardConvMB2 = convLayerMB2(forwardConvM2)\n",
    "reverseConvMB2 = convLayerMB2(reverseConvM2)\n",
    "\n",
    "convLayerMA2 = keras.layers.Activation(activation=\"relu\")\n",
    "forwardConvMA2 = convLayerMA2(forwardConvMB2)\n",
    "reverseConvMA2 = convLayerMA2(reverseConvMB2)\n",
    "\n",
    "reverseFlip2M = keras.layers.Lambda(lambda x: K.reverse(x,axes=1))(reverseConvMA2)\n",
    "\n",
    "forrevConcatM = keras.layers.Concatenate(axis=1)([forwardConvMA2, reverseFlip2M])\n",
    "\n",
    "poolLayerM = keras.layers.GlobalMaxPool1D()(forrevConcatM)\n",
    "\n",
    "convLayerA = keras.layers.Conv1D(200, 21, kernel_initializer=\"he_uniform\", padding=\"valid\")\n",
    "forwardConvA = convLayerM(forwardInput)\n",
    "reverseConvA = convLayerM(reverseFlip1)\n",
    "\n",
    "convLayerAB1 = keras.layers.BatchNormalization()\n",
    "forwardConvAB1 = convLayerAB1(forwardConvA)\n",
    "reverseConvAB1 = convLayerAB1(reverseConvA)\n",
    "\n",
    "convLayerAA1 = keras.layers.Activation(activation=\"relu\")\n",
    "forwardConvAA1 = convLayerAA1(forwardConvAB1)\n",
    "reverseConvAA1 = convLayerAA1(reverseConvAB1)\n",
    "\n",
    "convLayerA2 = keras.layers.Conv1D(200, 1, kernel_initializer=\"he_uniform\", padding=\"valid\")\n",
    "forwardConvA2 = convLayerM2(forwardConvAA1)\n",
    "reverseConvA2 = convLayerM2(reverseConvAA1)\n",
    "\n",
    "convLayerAB2 = keras.layers.BatchNormalization()\n",
    "forwardConvAB2 = convLayerAB2(forwardConvA2)\n",
    "reverseConvAB2 = convLayerAB2(reverseConvA2)\n",
    "\n",
    "convLayerAA2 = keras.layers.Activation(activation=\"relu\")\n",
    "forwardConvAA2 = convLayerMA2(forwardConvAB2)\n",
    "reverseConvAA2 = convLayerMA2(reverseConvAB2)\n",
    "\n",
    "reverseFlip2A = keras.layers.Lambda(lambda x: K.reverse(x,axes=1))(reverseConvAA2)\n",
    "\n",
    "forrevConcatA = keras.layers.Concatenate(axis=1)([forwardConvAA2, reverseFlip2A])\n",
    "\n",
    "poolLayerA = keras.layers.GlobalAveragePooling1D()(forrevConcatA)\n",
    "\n",
    "combineLayer = keras.layers.Concatenate()([poolLayerM, poolLayerA])\n",
    "drop1 = keras.layers.Dropout(0.5)(combineLayer)\n",
    "midLayer = keras.layers.Dense(400, activation=\"relu\", kernel_initializer=\"he_uniform\")(drop1)\n",
    "drop2 = keras.layers.Dropout(0.5)(midLayer)\n",
    "midLayer2 = keras.layers.Dense(400, activation=\"relu\", kernel_initializer=\"he_uniform\")(drop2)\n",
    "drop3 = keras.layers.Dropout(0.5)(midLayer2)\n",
    "midLayer3 = keras.layers.Dense(400, activation=\"relu\", kernel_initializer=\"he_uniform\")(drop3)\n",
    "drop4 = keras.layers.Dropout(0.5)(midLayer3)\n",
    "outLayer = keras.layers.Dense(1, activation=\"sigmoid\")(drop4)\n",
    "\n",
    "model = keras.models.Model(inputs=[forwardInput, reverseInput],\n",
    "                           outputs=[outLayer])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam() \n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([forward[trainMol,:,:], reverse[trainMol,:,:]], sampB[trainMol,:],\n",
    "                    batch_size=32, epochs=40, shuffle=True, verbose=0,\n",
    "                    validation_data=([forward[validMol,:,:], reverse[validMol,:,:]],\n",
    "                                     sampB[validMol,:]),\n",
    "                    callbacks=[earlystop, TqdmCallback(verbose=1, miniters=40, mininterval=0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and validation molecules\n",
    "\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_trainMol_idx' % \n",
    "        (sampleRef['cell'][samp]), trainMol)\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_trainMol_forward' % \n",
    "        (sampleRef['cell'][samp]), forward[trainMol,:,:])\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_trainMol_reverse' % \n",
    "        (sampleRef['cell'][samp]), reverse[trainMol,:,:])\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_trainMol_sampB' % \n",
    "        (sampleRef['cell'][samp]), sampB[trainMol,:])\n",
    "\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_validMol_idx' % \n",
    "        (sampleRef['cell'][samp]), validMol)\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_validMol_forward' % \n",
    "        (sampleRef['cell'][samp]), forward[validMol,:,:])\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_validMol_reverse' % \n",
    "        (sampleRef['cell'][samp]), reverse[validMol,:,:])\n",
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_validMol_sampB' % \n",
    "        (sampleRef['cell'][samp]), sampB[validMol,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 14\n",
    "\n",
    "model.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC' % (sampleRef['cell'][samp]))\n",
    "np.save((dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_history' % \n",
    "         (sampleRef['cell'][samp])),history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_preds = model.predict([forward[validMol,:,:], reverse[validMol,:,:]], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(dataPBase + '%s/processed/NNmodels/brduModel_230619_s1_cnn2_t2_forROC_validMol_preds' % \n",
    "        (sampleRef['cell'][samp]), v_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc for validation data \n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(sampB[validMol,:].astype(int),  v_preds)\n",
    "auc = metrics.roc_auc_score(sampB[validMol,:].astype(int),  v_preds)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,1,21)\n",
    "binc = bins[0:-1] + (bins[1]-bins[0])/2\n",
    "samphd = {}\n",
    "for samp in usesamples:\n",
    "    hist, bine = np.histogram(preds[sampO == samp], bins=bins, density=True)\n",
    "    samphd[samp] = hist\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for isamp, samp in enumerate(usesamples):\n",
    "    if isamp < 9:\n",
    "        plt.plot(binc, samphd[samp], label=sampleRef['sampleName'][samp])\n",
    "    else:\n",
    "        plt.plot(binc, samphd[samp], label=sampleRef['sampleName'][samp], ls='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, set chunk size, and define function\n",
    "\n",
    "savesamp = 14\n",
    "brdumodel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/brduModel_220919_s1_cnn2_t2' % \n",
    "                                    (sampleRef['cell'][savesamp]))\n",
    "\n",
    "chunksize = 150000\n",
    "\n",
    "def predictBrdU(samp):\n",
    "    with np.load(os.path.join(dataPBase, sampleRef['cell'][samp],'processed','forNN','{0}_{1}_forCNN_preds.npz'.format(sampleRef['cell'][samp],sampleRef['sampleName'][samp]))) as data:\n",
    "\n",
    "        print('dimension of npz file is: ' + str(data['forwardIPD'].shape))\n",
    "        print('number of 500 bp chunks is: ' + str(data['zmwNum'].shape[0]))\n",
    "        top = math.ceil(data['zmwNum'].shape[0]/chunksize) # number of iterations of 10,000 500 bp chunks\n",
    "        print('number of loops is: ' + str(top))\n",
    "\n",
    "        rem = data['zmwNum'].shape[0] - ((top-1) * chunksize) # number of chunks on the last iteration\n",
    "        print('remainder is: ' + str(rem))\n",
    "\n",
    "        end = chunksize\n",
    "        start = 0\n",
    "        cycle = 0\n",
    "\n",
    "        print('starting loop')\n",
    "        \n",
    "        for i in range (0, top):\n",
    "            \n",
    "            if cycle == top - 1:\n",
    "                end = start + rem\n",
    "            \n",
    "            print('starting index: ' + str(start))\n",
    "            print('ending index: ' + str(end))\n",
    "            \n",
    "            forward = np.concatenate([data['forwardIPD'][start:end] - 1,\n",
    "                                      (data['forwardNsub'][start:end] - 25) / 100,\n",
    "                                      data['forwardSeq'][start:end]], axis=2)\n",
    "            print('forward concatenated' + str(len(forward)))\n",
    "            reverse = np.concatenate([data['reverseIPD'][start:end] - 1,\n",
    "                                      (data['reverseNsub'][start:end] - 25) / 100,\n",
    "                                      data['reverseSeq'][start:end]], axis=2)\n",
    "            print('reverse concatenated')\n",
    "            \n",
    "            zmwN = data['zmwNum'][start:end]\n",
    "            print('num')\n",
    "            zmwP = data['zmwStartPos'][start:end]\n",
    "            print('start')\n",
    "            \n",
    "            # run predictions\n",
    "            prs = brdumodel.predict([forward, reverse], batch_size=1024, verbose=1)\n",
    "\n",
    "            # save predictions\n",
    "            # turn predictions into a format to save\n",
    "\n",
    "            zmwIx = {}\n",
    "            lastzmw = None\n",
    "            for i in range(zmwN.shape[0]):\n",
    "                thiszmw = zmwN[i,0]\n",
    "                if thiszmw != lastzmw:\n",
    "                    zmwIx[thiszmw] = [i]\n",
    "                else:\n",
    "                    zmwIx[thiszmw].append(i)\n",
    "                lastzmw = thiszmw\n",
    "\n",
    "            zmws = list(zmwIx.keys())\n",
    "            zmws = sorted(zmws)\n",
    "\n",
    "            brduPD = {}\n",
    "            for zmw in zmws:\n",
    "                startp = [zmwP[ix,0] for ix in zmwIx[zmw]]\n",
    "                maxstartp = np.max(startp)\n",
    "                brduRawp = np.full((len(startp), maxstartp+500), np.nan, dtype=np.float32)\n",
    "                for eix, ix in enumerate(zmwIx[zmw]):\n",
    "                    brduRawp[eix,zmwP[ix,0]:(zmwP[ix,0]+500)] = prs[ix]\n",
    "                brduPD[zmw] = np.nanmean(brduRawp, axis=0)\n",
    "\n",
    "            if not os.path.exists(dataPBase + '%s/processed/brduPrediction' % (sampleRef['cell'][samp])):\n",
    "                os.makedirs(dataPBase + '%s/processed/brduPrediction' % (sampleRef['cell'][samp]))\n",
    "                \n",
    "            piece = \"{:0>3d}\".format(cycle)\n",
    "\n",
    "            outf = '{0}{1}/processed/brduPrediction/{1}_{2}_brdu_220919_s1_cnn2_t2_adj_piece{3}.pickle'.format(dataPBase,\n",
    "                                                                                     sampleRef['cell'][samp],\n",
    "                                                                                     sampleRef['sampleName'][samp],piece)\n",
    "            print(outf)\n",
    "            with open(outf, 'wb') as fout:\n",
    "                pickle.dump(brduPD, fout, protocol=4)\n",
    "                \n",
    "            \n",
    "            # iterate through chunks\n",
    "            start += chunksize\n",
    "            end += chunksize\n",
    "            \n",
    "            cycle += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function that actually makes the predictions\n",
    "\n",
    "usesamples = range(0,10)\n",
    "\n",
    "for samp in usesamples:\n",
    "    predictBrdU(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite all piece files into one prediction file\n",
    "\n",
    "for samp in range(0,10):\n",
    "    predDict={}\n",
    "    binmol = {}\n",
    "    \n",
    "    predPieces = glob.glob('{0}{1}/processed/brduPrediction/{1}_{2}_brdu_220919_s1_cnn2_t2_adj_piece*.pickle'.format(dataPBase,\n",
    "                                                                                        sampleRef['cell'][samp],\n",
    "                                                                                        sampleRef['sampleName'][samp]))\n",
    "    predPieces = sorted(predPieces)\n",
    "    \n",
    "    for piece in tqdm(predPieces, position=0):\n",
    "        with open(piece,'rb') as fopen:\n",
    "            predPart = pickle.load(fopen)\n",
    "        predDict.update(predPart)\n",
    "        \n",
    "\n",
    "    # save the output as a file\n",
    "    with open(dataPBase + '{0}/processed/brduPrediction/{0}_{1}_brdu_220919_s1_cnn2_t2_adj.pickle'.format(sampleRef['cell'][samp],\n",
    "                                                                                          sampleRef['sampleName'][samp]), 'wb') as fout:\n",
    "        pickle.dump(predDict, fout, protocol=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
